{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSM Math: Week 6\n",
    "## Rebekah Dix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine implements the steepest descent method for quadratic functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steep_des(xinit, Q, b, c, tol, maxIter=5000):\n",
    "    \"\"\"\n",
    "    This function implements the steepest descent method for quadratic functions.\n",
    "    \"\"\"\n",
    "    it = 1\n",
    "    fonc = tol + 1\n",
    "    xk = xinit\n",
    "    \n",
    "    while it < maxIter and fonc > tol:\n",
    "        \n",
    "        DfT = Q @ xk - b\n",
    "        Df = DfT.T\n",
    "        \n",
    "        alphak = (Df @ DfT) / (Df @ Q @ DfT)\n",
    "        \n",
    "        xkp1 = xk - alphak * DfT\n",
    "        \n",
    "        fonc = np.linalg.norm(Df)\n",
    "        \n",
    "        xk = xkp1\n",
    "        \n",
    "        it += 1\n",
    "        \n",
    "    return xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[3, 1], [1, 1]])\n",
    "b = np.array([1, 6])\n",
    "c = 2\n",
    "xinit = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.4999953,  8.4999953])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steep_des(xinit, Q, b, c, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare with scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad(x, *args):\n",
    "    Q, b, c = args\n",
    "    return .5 * x.T @ Q @ x - b.T @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -22.250000\n",
      "         Iterations: 104\n",
      "         Function evaluations: 196\n"
     ]
    }
   ],
   "source": [
    "args = Q, b, c\n",
    "res = opt.minimize(quad, xinit, args=args, method='nelder-mead', options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.49999999,  8.5       ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It matches, but floating point/rounding errors appear to be an issue in both methods (but more so in mine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.828427124746191"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.cond(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine computes $Df$ using forward differences and a step size of $\\sqrt{\\text{Rerr}}_f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Df(f, x, Rerr):\n",
    "    \"\"\"\n",
    "    This function computes the gradient of f using forward differences.\n",
    "    \n",
    "    Inputs:\n",
    "        f : a callable function, from R^n to R\n",
    "        x (vector): a point in R^n\n",
    "        Rerr (scalar): an estimate for the maximum relative error of f near x\n",
    "                       Note, Rerr > e_machine\n",
    "    Returns:\n",
    "        Df(x) (vector): an estimate to the gradient of f at x\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    Df = np.zeros(n, dtype=np.float64)\n",
    "    h = 2 * np.sqrt(Rerr)\n",
    "    for ii in range(n):\n",
    "        eii = np.eye(n)[:,ii]\n",
    "        # First order forward difference:\n",
    "        #Df[ii] = (f(x + h * eii) - f(x)) / (h)\n",
    "        # Second order forward difference:\n",
    "        Df[ii] = (-3 * f(x) + 4 * f(x + h * eii) - f(x + 2 * h * eii)) / (2 * h)\n",
    "    return Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this function, I'll use the Rosenbrock function and compare with a scipy routine. Note, I found that my function was more accurate when I used a second order forward difference rather than a first order forward difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    return 100 * (x[1] - x[0] ** 2) ** 2 + (1 - x[0]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1605.3648,  -400.    ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-2, 2])\n",
    "compute_Df(rosenbrock, x, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1605.799908,  -399.99    ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.approx_fprime(x, rosenbrock, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant(x, x1, eps, fprime):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x : vector, one initial guess\n",
    "        x1 : vector, another initial guess\n",
    "        eps: desired level of accuracy\n",
    "        fprime : callable function, derivative of f\n",
    "    \n",
    "    Returns:\n",
    "        xk1 : vector, an approximation to a minimizer of f\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    MaxIter = 3000\n",
    "    it = 1\n",
    "    \n",
    "    xkm1 = x\n",
    "    xk = x1\n",
    "    \n",
    "    converged = False\n",
    "    while not converged and it < MaxIter:\n",
    "        \n",
    "        update = fprime(xk) * ((xk - xkm1) / (fprime(xk) - fprime(xkm1)))\n",
    "        xk1 = xk - update\n",
    "                               \n",
    "        if np.abs(xk1 - xk) < np.abs(xk) * eps:\n",
    "            converged = True\n",
    "        else: \n",
    "            converged = False\n",
    "        \n",
    "        xkm1 = xk\n",
    "        xk = xk1\n",
    "        \n",
    "        it = it + 1\n",
    "    \n",
    "    return xk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_des(f, x, eps):\n",
    "    \"\"\"\n",
    "    This function implements the steepest descent method\n",
    "    for arbitary functions.\n",
    "    \n",
    "    Inputs:\n",
    "        f : a callable function\n",
    "        x : a vector of length n; the starting point\n",
    "        eps : a \"small number\"\n",
    "        \n",
    "    Returns:\n",
    "        x_min : a vector which is a close approximation \n",
    "                to the local minimzer x* of f\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    maxiter = 30000\n",
    "    it = 1\n",
    "    err = 1 + eps\n",
    "    \n",
    "    xk = x\n",
    "    \n",
    "    while err > eps and it < maxiter:\n",
    "        \n",
    "        Dfxk = compute_Df(f, xk, eps)\n",
    "        f_alpha_prime = lambda x: compute_Df(f, xk - x * Dfxk.T, eps) @ (-1 * Dfxk.T)\n",
    "        opt_alpha = secant(.8, .2, eps, f_alpha_prime)\n",
    "        xkp1 = xk - opt_alpha * Dfxk\n",
    "        err = np.linalg.norm(Dfxk)\n",
    "        xk = xkp1\n",
    "        it += 1\n",
    "    \n",
    "    return xk, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.01634609, 1.03295939]), 9.999160234476975e-06)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = steepest_des(rosenbrock, x, 1e-5)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00026719471264171474"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosenbrock(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999575, 0.99999152])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = opt.minimize(rosenbrock, x, method='BFGS')\n",
    "compare.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.809703286310819e-11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosenbrock(compare.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My function approximately reaches the minimum at $(1,1)$ with value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
